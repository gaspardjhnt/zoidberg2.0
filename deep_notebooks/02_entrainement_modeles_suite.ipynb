{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement des modèles pour la détection de pneumonie (Suite)\n",
    "\n",
    "Ce notebook est la suite du notebook `02_entrainement_modeles.ipynb` et se concentre sur l'entraînement et l'évaluation des modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Pour éviter les avertissements\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration de l'affichage\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entraînement des modèles\n",
    "\n",
    "Nous allons maintenant entraîner les différents modèles que nous avons créés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données préparées dans le notebook précédent\n",
    "# Si vous exécutez ce notebook séparément, vous devrez d'abord exécuter le code de chargement des données\n",
    "# du notebook précédent ou charger les données à partir d'un fichier sauvegardé\n",
    "\n",
    "# Fonction pour entraîner un modèle\n",
    "def train_model(model, X_train, y_train, X_val, y_val, model_name='model', \n",
    "                batch_size=32, epochs=20, use_augmentation=True):\n",
    "    \"\"\"\n",
    "    Entraîne un modèle avec ou sans augmentation de données.\n",
    "    \n",
    "    Args:\n",
    "        model: Modèle à entraîner\n",
    "        X_train (numpy.ndarray): Images d'entraînement\n",
    "        y_train (numpy.ndarray): Étiquettes d'entraînement\n",
    "        X_val (numpy.ndarray): Images de validation\n",
    "        y_val (numpy.ndarray): Étiquettes de validation\n",
    "        model_name (str): Nom du modèle pour la sauvegarde\n",
    "        batch_size (int): Taille du batch\n",
    "        epochs (int): Nombre d'époques\n",
    "        use_augmentation (bool): Utiliser l'augmentation de données\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Modèle entraîné et historique d'entraînement\n",
    "    \"\"\"\n",
    "    # Vérifier si les données d'entraînement sont disponibles\n",
    "    if len(X_train) == 0 or len(y_train) == 0:\n",
    "        print(\"Erreur: Données d'entraînement vides.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Créer le répertoire de résultats s'il n'existe pas\n",
    "    results_dir = r'C:\\Users\\Krikri\\Documents\\EPITECH\\MSc\\Msc1\\T-DEV-810-PAR-29\\epitech_docs\\detection_pneumonie_ia\\results'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Définir les callbacks\n",
    "    callbacks = [\n",
    "        # Sauvegarde du meilleur modèle\n",
    "        ModelCheckpoint(\n",
    "            filepath=os.path.join(results_dir, f'{model_name}.h5'),\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        # Arrêt anticipé si pas d'amélioration\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            verbose=1,\n",
    "            restore_best_weights=True  # Restaurer les meilleurs poids\n",
    "        ),\n",
    "        # Réduction du taux d'apprentissage si plateau\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=3,\n",
    "            verbose=1,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(f\"Début de l'entraînement du modèle {model_name}...\")\n",
    "    print(f\"Nombre d'images d'entraînement: {len(X_train)}\")\n",
    "    print(f\"Nombre d'images de validation: {len(X_val)}\")\n",
    "    print(f\"Utilisation de l'augmentation de données: {use_augmentation}\")\n",
    "    \n",
    "    try:\n",
    "        # Entraînement avec ou sans augmentation de données\n",
    "        if use_augmentation:\n",
    "            # Configurer le générateur d'augmentation\n",
    "            datagen = ImageDataGenerator(\n",
    "                rotation_range=15,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                shear_range=0.1,\n",
    "                zoom_range=0.1,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "            \n",
    "            # Adapter le générateur aux données d'entraînement\n",
    "            datagen.fit(X_train)\n",
    "            \n",
    "            # Calculer le nombre d'étapes par époque\n",
    "            steps_per_epoch = len(X_train) // batch_size\n",
    "            if steps_per_epoch == 0:  # Éviter les divisions par zéro\n",
    "                steps_per_epoch = 1\n",
    "            \n",
    "            # Entraîner le modèle avec le générateur\n",
    "            history = model.fit(\n",
    "                datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=epochs,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "        else:\n",
    "            # Entraîner le modèle sans augmentation\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "        \n",
    "        print(f\"Entraînement terminé après {len(history.epoch)} époques.\")\n",
    "        \n",
    "        # Vérifier si le fichier du modèle existe\n",
    "        model_path = os.path.join(results_dir, f'{model_name}.h5')\n",
    "        if os.path.exists(model_path):\n",
    "            # Charger le meilleur modèle\n",
    "            print(f\"Chargement du meilleur modèle depuis {model_path}\")\n",
    "            best_model = load_model(model_path)\n",
    "            return best_model, history\n",
    "        else:\n",
    "            print(f\"Attention: Le fichier du modèle {model_path} n'a pas été créé.\")\n",
    "            return model, history  # Retourner le modèle actuel\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'entraînement du modèle {model_name}: {e}\")\n",
    "        return model, None  # Retourner le modèle non entraîné en cas d'erreur\n",
    "\n",
    "# Fonction pour visualiser l'historique d'entraînement\n",
    "def plot_training_history(history, model_name='Modèle'):\n",
    "    \"\"\"\n",
    "    Visualise l'historique d'entraînement d'un modèle.\n",
    "    \n",
    "    Args:\n",
    "        history: Historique d'entraînement\n",
    "        model_name (str): Nom du modèle\n",
    "    \"\"\"\n",
    "    # Vérifier si l'historique est valide\n",
    "    if history is None or not hasattr(history, 'history') or not history.history:\n",
    "        print(f\"Aucun historique d'entraînement valide disponible pour {model_name}.\")\n",
    "        return\n",
    "    \n",
    "    # Créer une figure avec deux sous-graphiques\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Graphique de l'accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Entraînement')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "    ax1.set_title(f'Accuracy - {model_name}')\n",
    "    ax1.set_xlabel('Époque')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Graphique de la loss\n",
    "    ax2.plot(history.history['loss'], label='Entraînement')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation')\n",
    "    ax2.set_title(f'Loss - {model_name}')\n",
    "    ax2.set_xlabel('Époque')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Afficher des informations supplémentaires sur la convergence\n",
    "    epochs = len(history.history['accuracy'])\n",
    "    final_train_acc = history.history['accuracy'][-1]\n",
    "    final_val_acc = history.history['val_accuracy'][-1]\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_val_loss = history.history['val_loss'][-1]\n",
    "    \n",
    "    print(f\"\\nRésumé de l'entraînement pour {model_name}:\")\n",
    "    print(f\"Nombre total d'époques: {epochs}\")\n",
    "    print(f\"Accuracy finale - Entraînement: {final_train_acc:.4f}, Validation: {final_val_acc:.4f}\")\n",
    "    print(f\"Loss finale - Entraînement: {final_train_loss:.4f}, Validation: {final_val_loss:.4f}\")\n",
    "    \n",
    "    # Vérifier si l'entraînement a convergé\n",
    "    if epochs > 5:\n",
    "        last_val_losses = history.history['val_loss'][-5:]\n",
    "        loss_change = (last_val_losses[-1] - last_val_losses[0]) / last_val_losses[0]\n",
    "        \n",
    "        if abs(loss_change) < 0.01:\n",
    "            print(\"L'entraînement a convergé (variation de loss < 1% sur les 5 dernières époques).\")\n",
    "        elif loss_change > 0:\n",
    "            print(\"Attention: La loss de validation augmente, ce qui peut indiquer un surapprentissage.\")\n",
    "        else:\n",
    "            print(\"L'entraînement pourrait bénéficier de plus d'époques (la loss continue de diminuer).\")\n",
    "    \n",
    "    # Vérifier l'écart entre l'entraînement et la validation\n",
    "    train_val_acc_gap = final_train_acc - final_val_acc\n",
    "    if train_val_acc_gap > 0.1:\n",
    "        print(f\"Attention: Écart important entre l'accuracy d'entraînement et de validation ({train_val_acc_gap:.4f}), possible surapprentissage.\")\n",
    "\n",
    "# Fonction pour vérifier l'état d'avancement de l'entraînement\n",
    "def check_training_status(model_name='model'):\n",
    "    \"\"\"\n",
    "    Vérifie si un modèle a été entraîné et sauvegardé.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Nom du modèle\n",
    "        \n",
    "    Returns:\n",
    "        bool: True si le modèle est entraîné, False sinon\n",
    "    \"\"\"\n",
    "    results_dir = r'C:\\Users\\Krikri\\Documents\\EPITECH\\MSc\\Msc1\\T-DEV-810-PAR-29\\epitech_docs\\detection_pneumonie_ia\\results'\n",
    "    model_path = os.path.join(results_dir, f'{model_name}.h5')\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        model_size = os.path.getsize(model_path) / (1024 * 1024)  # Taille en MB\n",
    "        print(f\"Le modèle {model_name} est entraîné et sauvegardé ({model_size:.2f} MB).\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Le modèle {model_name} n'est pas encore entraîné ou n'a pas été sauvegardé.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Entraînement du CNN simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si les données sont disponibles\n",
    "if len(X_train) == 0 or len(X_val) == 0:\n",
    "    print(\"Erreur: Les données d'entraînement ou de validation sont vides.\")\n",
    "    print(\"Veuillez d'abord exécuter le code de chargement des données.\")\n",
    "else:\n",
    "    try:\n",
    "        # Créer le modèle CNN\n",
    "        print(\"Création du modèle CNN...\")\n",
    "        cnn_model = create_cnn_model(input_shape=(224, 224, 3))\n",
    "        \n",
    "        # Afficher le résumé du modèle\n",
    "        print(\"\\nRésumé du modèle CNN:\")\n",
    "        cnn_model.summary()\n",
    "        \n",
    "        # Vérifier si le modèle est déjà entraîné\n",
    "        results_dir = r'C:\\Users\\Krikri\\Documents\\EPITECH\\MSc\\Msc1\\T-DEV-810-PAR-29\\epitech_docs\\detection_pneumonie_ia\\results'\n",
    "        model_path = os.path.join(results_dir, 'cnn_model.h5')\n",
    "        \n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"\\nLe modèle CNN est déjà entraîné. Voulez-vous le charger? (y/n)\")\n",
    "            # Dans un notebook interactif, vous pourriez utiliser input() ici\n",
    "            # Comme c'est un script, nous supposons que nous voulons réentraîner\n",
    "            load_existing = False\n",
    "            \n",
    "            if load_existing:\n",
    "                print(\"Chargement du modèle CNN existant...\")\n",
    "                cnn_model = load_model(model_path)\n",
    "                print(\"Modèle chargé avec succès.\")\n",
    "                \n",
    "                # Pour visualiser l'historique, nous aurions besoin de le charger séparément\n",
    "                # car il n'est pas sauvegardé avec le modèle\n",
    "                print(\"Note: L'historique d'entraînement n'est pas disponible pour un modèle chargé.\")\n",
    "            else:\n",
    "                # Entraîner le modèle\n",
    "                print(\"\\nRéentraînement du modèle CNN...\")\n",
    "                cnn_model, cnn_history = train_model(\n",
    "                    cnn_model, X_train, y_train, X_val, y_val,\n",
    "                    model_name='cnn_model',\n",
    "                    batch_size=32,\n",
    "                    epochs=20,\n",
    "                    use_augmentation=True\n",
    "                )\n",
    "                \n",
    "                # Visualiser l'historique d'entraînement\n",
    "                if cnn_history is not None:\n",
    "                    plot_training_history(cnn_history, model_name='CNN')\n",
    "                else:\n",
    "                    print(\"Erreur: L'entraînement n'a pas produit d'historique valide.\")\n",
    "        else:\n",
    "            # Entraîner le modèle\n",
    "            print(\"\\nEntraînement du modèle CNN...\")\n",
    "            cnn_model, cnn_history = train_model(\n",
    "                cnn_model, X_train, y_train, X_val, y_val,\n",
    "                model_name='cnn_model',\n",
    "                batch_size=32,\n",
    "                epochs=20,\n",
    "                use_augmentation=True\n",
    "            )\n",
    "            \n",
    "            # Visualiser l'historique d'entraînement\n",
    "            if cnn_history is not None:\n",
    "                plot_training_history(cnn_history, model_name='CNN')\n",
    "            else:\n",
    "                print(\"Erreur: L'entraînement n'a pas produit d'historique valide.\")\n",
    "        \n",
    "        # Vérifier si le modèle est bien entraîné\n",
    "        if cnn_model is not None:\n",
    "            print(\"\\nÉvaluation du modèle CNN sur l'ensemble de validation...\")\n",
    "            val_loss, val_acc = cnn_model.evaluate(X_val, y_val, verbose=1)\n",
    "            print(f\"Validation - Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "            \n",
    "            # Faire des prédictions sur quelques exemples\n",
    "            if len(X_val) > 0:\n",
    "                print(\"\\nPrédictions sur quelques exemples de validation:\")\n",
    "                num_examples = min(5, len(X_val))\n",
    "                pred_indices = np.random.choice(len(X_val), num_examples, replace=False)\n",
    "                \n",
    "                for i, idx in enumerate(pred_indices):\n",
    "                    img = X_val[idx]\n",
    "                    true_label = y_val[idx]\n",
    "                    pred_prob = cnn_model.predict(np.expand_dims(img, axis=0))[0][0]\n",
    "                    pred_label = 1 if pred_prob > 0.5 else 0\n",
    "                    \n",
    "                    print(f\"Exemple {i+1}: Vraie classe = {'Pneumonie' if true_label == 1 else 'Normal'}, \"\n",
    "                          f\"Prédiction = {'Pneumonie' if pred_label == 1 else 'Normal'} \"\n",
    "                          f\"(confiance: {pred_prob:.2f})\")\n",
    "        else:\n",
    "            print(\"Erreur: Le modèle CNN n'a pas été correctement créé ou entraîné.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur s'est produite lors de la création ou de l'entraînement du modèle CNN: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Entraînement du modèle VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si les données sont disponibles\n",
    "if len(X_train) == 0 or len(X_val) == 0:\n",
    "    print(\"Erreur: Les données d'entraînement ou de validation sont vides.\")\n",
    "    print(\"Veuillez d'abord exécuter le code de chargement des données.\")\n",
    "else:\n",
    "    try:\n",
    "        # Vérifier si le modèle est déjà entraîné\n",
    "        results_dir = r'C:\\Users\\Krikri\\Documents\\EPITECH\\MSc\\Msc1\\T-DEV-810-PAR-29\\epitech_docs\\detection_pneumonie_ia\\results'\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        model_path = os.path.join(results_dir, 'vgg16_model.h5')\n",
    "        \n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"\\nLe modèle VGG16 est déjà entraîné. Voulez-vous le charger? (y/n)\")\n",
    "            # Dans un notebook interactif, vous pourriez utiliser input() ici\n",
    "            # Comme c'est un script, nous supposons que nous voulons réentraîner\n",
    "            load_existing = False\n",
    "            \n",
    "            if load_existing:\n",
    "                print(\"Chargement du modèle VGG16 existant...\")\n",
    "                vgg16_model = load_model(model_path)\n",
    "                print(\"Modèle chargé avec succès.\")\n",
    "                \n",
    "                # Pour visualiser l'historique, nous aurions besoin de le charger séparément\n",
    "                print(\"Note: L'historique d'entraînement n'est pas disponible pour un modèle chargé.\")\n",
    "            else:\n",
    "                # Créer le modèle VGG16\n",
    "                print(\"Création du modèle VGG16...\")\n",
    "                vgg16_model = create_vgg16_model(input_shape=(224, 224, 3))\n",
    "                \n",
    "                # Afficher un résumé simplifié du modèle (VGG16 a beaucoup de couches)\n",
    "                print(\"\\nRésumé du modèle VGG16:\")\n",
    "                print(f\"Nombre total de couches: {len(vgg16_model.layers)}\")\n",
    "                print(f\"Nombre de paramètres: {vgg16_model.count_params():,}\")\n",
    "                print(\"Architecture: VGG16 (base) + Flatten + Dense(512) + BatchNorm + Dropout(0.5) + Dense(1, sigmoid)\")\n",
    "                \n",
    "                # Entraîner le modèle\n",
    "                print(\"\\nRéentraînement du modèle VGG16...\")\n",
    "                # Libérer la mémoire avant l'entraînement\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                tf.keras.backend.clear_session()\n",
    "                \n",
    "                vgg16_model, vgg16_history = train_model(\n",
    "                    vgg16_model, X_train, y_train, X_val, y_val,\n",
    "                    model_name='vgg16_model',\n",
    "                    batch_size=16,  # Batch size plus petit pour VGG16 (modèle plus grand)\n",
    "                    epochs=15,\n",
    "                    use_augmentation=True\n",
    "                )\n",
    "                \n",
    "                # Visualiser l'historique d'entraînement\n",
    "                if vgg16_history is not None:\n",
    "                    plot_training_history(vgg16_history, model_name='VGG16')\n",
    "                else:\n",
    "                    print(\"Erreur: L'entraînement n'a pas produit d'historique valide.\")\n",
    "        else:\n",
    "            # Créer le modèle VGG16\n",
    "            print(\"Création du modèle VGG16...\")\n",
    "            vgg16_model = create_vgg16_model(input_shape=(224, 224, 3))\n",
    "            \n",
    "            # Afficher un résumé simplifié du modèle (VGG16 a beaucoup de couches)\n",
    "            print(\"\\nRésumé du modèle VGG16:\")\n",
    "            print(f\"Nombre total de couches: {len(vgg16_model.layers)}\")\n",
    "            print(f\"Nombre de paramètres: {vgg16_model.count_params():,}\")\n",
    "            print(\"Architecture: VGG16 (base) + Flatten + Dense(512) + BatchNorm + Dropout(0.5) + Dense(1, sigmoid)\")\n",
    "            \n",
    "            # Entraîner le modèle\n",
    "            print(\"\\nEntraînement du modèle VGG16...\")\n",
    "            # Libérer la mémoire avant l'entraînement\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            tf.keras.backend.clear_session()\n",
    "            \n",
    "            vgg16_model, vgg16_history = train_model(\n",
    "                vgg16_model, X_train, y_train, X_val, y_val,\n",
    "                model_name='vgg16_model',\n",
    "                batch_size=16,  # Batch size plus petit pour VGG16 (modèle plus grand)\n",
    "                epochs=15,\n",
    "                use_augmentation=True\n",
    "            )\n",
    "            \n",
    "            # Visualiser l'historique d'entraînement\n",
    "            if vgg16_history is not None:\n",
    "                plot_training_history(vgg16_history, model_name='VGG16')\n",
    "            else:\n",
    "                print(\"Erreur: L'entraînement n'a pas produit d'historique valide.\")\n",
    "        \n",
    "        # Vérifier si le modèle est bien entraîné\n",
    "        if vgg16_model is not None:\n",
    "            print(\"\\nÉvaluation du modèle VGG16 sur l'ensemble de validation...\")\n",
    "            val_loss, val_acc = vgg16_model.evaluate(X_val, y_val, verbose=1)\n",
    "            print(f\"Validation - Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "            \n",
    "            # Faire des prédictions sur quelques exemples\n",
    "            if len(X_val) > 0:\n",
    "                print(\"\\nPrédictions sur quelques exemples de validation:\")\n",
    "                num_examples = min(5, len(X_val))\n",
    "                pred_indices = np.random.choice(len(X_val), num_examples, replace=False)\n",
    "                \n",
    "                for i, idx in enumerate(pred_indices):\n",
    "                    img = X_val[idx]\n",
    "                    true_label = y_val[idx]\n",
    "                    pred_prob = vgg16_model.predict(np.expand_dims(img, axis=0))[0][0]\n",
    "                    pred_label = 1 if pred_prob > 0.5 else 0\n",
    "                    \n",
    "                    print(f\"Exemple {i+1}: Vraie classe = {'Pneumonie' if true_label == 1 else 'Normal'}, \"\n",
    "                          f\"Prédiction = {'Pneumonie' if pred_label == 1 else 'Normal'} \"\n",
    "                          f\"(confiance: {pred_prob:.2f})\")\n",
    "        else:\n",
    "            print(\"Erreur: Le modèle VGG16 n'a pas été correctement créé ou entraîné.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur s'est produite lors de la création ou de l'entraînement du modèle VGG16: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Entraînement du modèle ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si les données sont disponibles\n",
    "if len(X_train) == 0 or len(X_val) == 0:\n",
    "    print(\"Erreur: Les données d'entraînement ou de validation sont vides.\")\n",
    "    print(\"Veuillez d'abord exécuter le code de chargement des données.\")\n",
    "else:\n",
    "    try:\n",
    "        # Vérifier si le modèle est déjà entraîné\n",
    "        results_dir = r'C:\\Users\\Krikri\\Documents\\EPITECH\\MSc\\Msc1\\T-DEV-810-PAR-29\\epitech_docs\\detection_pneumonie_ia\\results'\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        model_path = os.path.join(results_dir, 'resnet50_model.h5')\n",
    "        \n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"\\nLe modèle ResNet50 est déjà entraîné. Voulez-vous le charger? (y/n)\")\n",
    "            # Dans un notebook interactif, vous pourriez utiliser input() ici\n",
    "            # Comme c'est un script, nous supposons que nous voulons réentraîner\n",
    "            load_existing = False\n",
    "            \n",
    "            if load_existing:\n",
    "                print(\"Chargement du modèle ResNet50 existant...\")\n",
    "                resnet50_model = load_model(model_path)\n",
    "                print(\"Modèle chargé avec succès.\")\n",
    "                \n",
    "                # Pour visualiser l'historique, nous aurions besoin de le charger séparément\n",
    "                print(\"Note: L'historique d'entraînement n'est pas disponible pour un modèle chargé.\")\n",
    "            else:\n",
    "                # Libérer la mémoire avant de créer un nouveau modèle\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                tf.keras.backend.clear_session()\n",
    "                \n",
    "                # Créer le modèle ResNet50\n",
    "                print(\"Création du modèle ResNet50...\")\n",
    "                resnet50_model = create_resnet50_model(input_shape=(224, 224, 3))\n",
    "                \n",
    "                # Afficher un résumé simplifié du modèle (ResNet50 a beaucoup de couches)\n",
    "                print(\"\\nRésumé du modèle ResNet50:\")\n",
    "                print(f\"Nombre total de couches: {len(resnet50_model.layers)}\")\n",
    "                print(f\"Nombre de paramètres: {resnet50_model.count_params():,}\")\n",
    "                print(\"Architecture: ResNet50 (base) + Flatten + Dense(512) + BatchNorm + Dropout(0.5) + Dense(1, sigmoid)\")\n",
    "                \n",
    "                # Entraîner le modèle\n",
    "                print(\"\\nRéentraînement du modèle ResNet50...\")\n",
    "                # Libérer la mémoire avant l'entraînement\n",
    "                gc.collect()\n",
    "                \n",
    "                # Réduire la taille du batch si nécessaire pour éviter les problèmes de mémoire\n",
    "                batch_size = 8  # Encore plus petit pour ResNet50 qui est très volumineux\n",
    "                \n",
    "                resnet50_model, resnet50_history = train_model(\n",
    "                    resnet50_model, X_train, y_train, X_val, y_val,\n",
    "                    model_name='resnet50_model',\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=15,\n",
    "                    use_augmentation=True\n",
    "                )\n",
    "                \n",
    "                # Visualiser l'historique d'entraînement\n",
    "                if resnet50_history is not None:\n",
    "                    plot_training_history(resnet50_history, model_name='ResNet50')\n",
    "                else:\n",
    "                    print(\"Erreur: L'entraînement n'a pas produit d'historique valide.\")\n",
    "        else:\n",
    "            # Libérer la mémoire avant de créer un nouveau modèle\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            tf.keras.backend.clear_session()\n",
    "            \n",
    "            # Créer le modèle ResNet50\n",
    "            print(\"Création du modèle ResNet50...\")\n",
    "            resnet50_model = create_resnet50_model(input_shape=(224, 224, 3))\n",
    "            \n",
    "            # Afficher un résumé simplifié du modèle (ResNet50 a beaucoup de couches)\n",
    "            print(\"\\nRésumé du modèle ResNet50:\")\n",
    "            print(f\"Nombre total de couches: {len(resnet50_model.layers)}\")\n",
    "            print(f\"Nombre de paramètres: {resnet50_model.count_params():,}\")\n",
    "            print(\"Architecture: ResNet50 (base) + Flatten + Dense(512) + BatchNorm + Dropout(0.5) + Dense(1, sigmoid)\")\n",
    "            \n",
    "            # Entraîner le modèle\n",
    "            print(\"\\nEntraînement du modèle ResNet50...\")\n",
    "            # Libérer la mémoire avant l'entraînement\n",
    "            gc.collect()\n",
    "            \n",
    "            # Réduire la taille du batch si nécessaire pour éviter les problèmes de mémoire\n",
    "            batch_size = 8  # Encore plus petit pour ResNet50 qui est très volumineux\n",
    "            \n",
    "            resnet50_model, resnet50_history = train_model(\n",
    "                resnet50_model, X_train, y_train, X_val, y_val,\n",
    "                model_name='resnet50_model',\n",
    "                batch_size=batch_size,\n",
    "                epochs=15,\n",
    "                use_augmentation=True\n",
    "            )\n",
    "            \n",
    "            # Visualiser l'historique d'entraînement\n",
    "            if resnet50_history is not None:\n",
    "                plot_training_history(resnet50_history, model_name='ResNet50')\n",
    "            else:\n",
    "                print(\"Erreur: L'entraînement n'a pas produit d'historique valide.\")\n",
    "        \n",
    "        # Vérifier si le modèle est bien entraîné\n",
    "        if resnet50_model is not None:\n",
    "            print(\"\\nÉvaluation du modèle ResNet50 sur l'ensemble de validation...\")\n",
    "            # Utiliser un batch_size plus petit pour l'évaluation aussi\n",
    "            val_loss, val_acc = resnet50_model.evaluate(X_val, y_val, batch_size=8, verbose=1)\n",
    "            print(f\"Validation - Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "            \n",
    "            # Faire des prédictions sur quelques exemples\n",
    "            if len(X_val) > 0:\n",
    "                print(\"\\nPrédictions sur quelques exemples de validation:\")\n",
    "                num_examples = min(5, len(X_val))\n",
    "                pred_indices = np.random.choice(len(X_val), num_examples, replace=False)\n",
    "                \n",
    "                for i, idx in enumerate(pred_indices):\n",
    "                    img = X_val[idx]\n",
    "                    true_label = y_val[idx]\n",
    "                    pred_prob = resnet50_model.predict(np.expand_dims(img, axis=0), batch_size=1)[0][0]\n",
    "                    pred_label = 1 if pred_prob > 0.5 else 0\n",
    "                    \n",
    "                    print(f\"Exemple {i+1}: Vraie classe = {'Pneumonie' if true_label == 1 else 'Normal'}, \"\n",
    "                          f\"Prédiction = {'Pneumonie' if pred_label == 1 else 'Normal'} \"\n",
    "                          f\"(confiance: {pred_prob:.2f})\")\n",
    "        else:\n",
    "            print(\"Erreur: Le modèle ResNet50 n'a pas été correctement créé ou entraîné.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur s'est produite lors de la création ou de l'entraînement du modèle ResNet50: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        print(\"\\nConseil: ResNet50 est un modèle très volumineux qui peut nécessiter beaucoup de mémoire.\")\n",
    "        print(\"Si vous rencontrez des problèmes de mémoire, essayez de:\")\n",
    "        print(\"1. Réduire la taille du batch (par exemple, batch_size=4)\")\n",
    "        print(\"2. Réduire la taille des images d'entrée (par exemple, input_shape=(150, 150, 3))\")\n",
    "        print(\"3. Utiliser moins d'images pour l'entraînement\")\n",
    "        print(\"4. Utiliser un modèle plus léger comme le CNN simple ou MobileNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Évaluation des modèles sur l'ensemble de test\n",
    "\n",
    "Nous allons maintenant évaluer les performances des modèles entraînés sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name='Modèle', class_names=['Normal', 'Pneumonie']):\n",
    "    \"\"\"\n",
    "    Évalue les performances d'un modèle sur l'ensemble de test.\n",
    "    \n",
    "    Args:\n",
    "        model: Modèle à évaluer\n",
    "        X_test (numpy.ndarray): Images de test\n",
    "        y_test (numpy.ndarray): Étiquettes de test\n",
    "        model_name (str): Nom du modèle\n",
    "        class_names (list): Noms des classes\n",
    "        \n",
    "    Returns:\n",
    "        dict: Métriques d'évaluation\n",
    "    \"\"\"\n",
    "    # Vérifier si le modèle est entraîné\n",
    "    if model is None:\n",
    "        print(f\"Le modèle {model_name} n'est pas disponible.\")\n",
    "        return None\n",
    "    \n",
    "    # Vérifier si les données de test sont disponibles\n",
    "    if len(X_test) == 0 or len(y_test) == 0:\n",
    "        print(f\"Les données de test sont vides. Impossible d'évaluer le modèle {model_name}.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Faire des prédictions\n",
    "        print(f\"Prédiction sur {len(X_test)} images de test...\")\n",
    "        # Utiliser un batch_size plus petit pour les modèles volumineux\n",
    "        batch_size = 16\n",
    "        if 'resnet' in model_name.lower() or 'vgg' in model_name.lower():\n",
    "            batch_size = 8\n",
    "        \n",
    "        y_pred_proba = model.predict(X_test, batch_size=batch_size, verbose=1)\n",
    "        \n",
    "        # S'assurer que y_pred_proba est un tableau 1D\n",
    "        if len(y_pred_proba.shape) > 1 and y_pred_proba.shape[1] > 1:\n",
    "            # Pour les modèles avec plusieurs sorties (softmax)\n",
    "            y_pred_proba = y_pred_proba[:, 1]\n",
    "        else:\n",
    "            # Pour les modèles avec une seule sortie (sigmoid)\n",
    "            y_pred_proba = y_pred_proba.flatten()\n",
    "            \n",
    "        y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "        \n",
    "        # Calculer les métriques\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1_score': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        # Afficher les résultats\n",
    "        print(f\"\\n=== Résultats d'évaluation pour {model_name} ===\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"F1-score: {metrics['f1_score']:.4f}\")\n",
    "        print(f\"AUC: {metrics['auc']:.4f}\")\n",
    "        \n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(\"\\nMatrice de confusion:\")\n",
    "        print(cm)\n",
    "        \n",
    "        # Vérifier si c'est bien une matrice 2x2 avant de la décomposer\n",
    "        if cm.shape == (2, 2):\n",
    "            # Calculer les valeurs pour la matrice de confusion\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            total = tn + fp + fn + tp\n",
    "            \n",
    "            print(f\"\\nDétails de la matrice de confusion:\")\n",
    "            print(f\"Vrais Négatifs (Normal correctement identifié): {tn} ({tn/total*100:.1f}%)\")\n",
    "            print(f\"Faux Positifs (Normal prédit comme Pneumonie): {fp} ({fp/total*100:.1f}%)\")\n",
    "            print(f\"Faux Négatifs (Pneumonie prédite comme Normal): {fn} ({fn/total*100:.1f}%)\")\n",
    "            print(f\"Vrais Positifs (Pneumonie correctement identifiée): {tp} ({tp/total*100:.1f}%)\")\n",
    "            \n",
    "            # Calculer des métriques supplémentaires\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "            npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative Predictive Value\n",
    "            \n",
    "            print(f\"\\nMétriques supplémentaires:\")\n",
    "            print(f\"Spécificité: {specificity:.4f}\")\n",
    "            print(f\"Valeur prédictive négative: {npv:.4f}\")\n",
    "        else:\n",
    "            print(\"Note: La matrice de confusion n'est pas de taille 2x2, certaines métriques détaillées ne sont pas calculées.\")\n",
    "        \n",
    "        # Rapport de classification\n",
    "        print(\"\\nRapport de classification:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "        \n",
    "        # Visualiser la matrice de confusion\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=class_names, \n",
    "                    yticklabels=class_names)\n",
    "        plt.xlabel('Prédiction')\n",
    "        plt.ylabel('Vérité terrain')\n",
    "        plt.title(f'Matrice de confusion - {model_name}')\n",
    "        \n",
    "        # Ajouter les pourcentages si c'est une matrice 2x2\n",
    "        if cm.shape == (2, 2):\n",
    "            for i in range(len(class_names)):\n",
    "                for j in range(len(class_names)):\n",
    "                    plt.text(j + 0.5, i + 0.7, f'({cm[i, j]/np.sum(cm)*100:.1f}%)', \n",
    "                             ha='center', va='center', color='black' if cm[i, j] < cm.max()/2 else 'white')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Courbe ROC\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {metrics[\"auc\"]:.4f}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Aléatoire (AUC = 0.5)')\n",
    "        plt.xlabel('Taux de faux positifs (1 - Spécificité)')\n",
    "        plt.ylabel('Taux de vrais positifs (Sensibilité)')\n",
    "        plt.title(f'Courbe ROC - {model_name}')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Ajouter quelques points de seuil sur la courbe ROC\n",
    "        # Vérifier que thresholds n'est pas vide\n",
    "        if len(thresholds) > 0:\n",
    "            # Sélectionner des seuils plus pertinents\n",
    "            threshold_points = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "            threshold_indices = []\n",
    "            \n",
    "            for t in threshold_points:\n",
    "                # Vérifier que les seuils sont dans la plage des valeurs de thresholds\n",
    "                if t >= min(thresholds) and t <= max(thresholds):\n",
    "                    # Trouver l'indice du seuil le plus proche\n",
    "                    idx = np.argmin(np.abs(thresholds - t))\n",
    "                    threshold_indices.append(idx)\n",
    "                \n",
    "            # Marquer les points de seuil sur la courbe s'il y en a\n",
    "            if threshold_indices:\n",
    "                plt.scatter(fpr[threshold_indices], tpr[threshold_indices], c='red', s=50)\n",
    "                \n",
    "                # Ajouter les annotations pour les seuils\n",
    "                for i, idx in enumerate(threshold_indices):\n",
    "                    plt.annotate(f'Seuil ≈ {thresholds[idx]:.2f}', \n",
    "                                (fpr[idx], tpr[idx]), \n",
    "                                xytext=(10, -10), \n",
    "                                textcoords='offset points',\n",
    "                                fontsize=8,\n",
    "                                arrowprops=dict(arrowstyle='->', color='red', lw=1))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Visualiser la distribution des probabilités prédites\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Séparer les prédictions par classe réelle\n",
    "        normal_probs = y_pred_proba[y_test == 0]\n",
    "        pneumonia_probs = y_pred_proba[y_test == 1]\n",
    "        \n",
    "        # Vérifier qu'il y a des exemples dans chaque classe\n",
    "        if len(normal_probs) > 0 and len(pneumonia_probs) > 0:\n",
    "            # Tracer les histogrammes\n",
    "            plt.hist(normal_probs, bins=20, alpha=0.5, color='blue', label=class_names[0])\n",
    "            plt.hist(pneumonia_probs, bins=20, alpha=0.5, color='red', label=class_names[1])\n",
    "            \n",
    "            plt.axvline(x=0.5, color='black', linestyle='--', label='Seuil (0.5)')\n",
    "            plt.xlabel('Probabilité prédite de pneumonie')\n",
    "            plt.ylabel('Nombre d\\'images')\n",
    "            plt.title(f'Distribution des probabilités prédites - {model_name}')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, \"Pas assez d'exemples pour afficher la distribution\", \n",
    "                    ha='center', va='center', fontsize=12)\n",
    "            plt.title(f'Distribution des probabilités prédites - {model_name}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Afficher des exemples de prédictions (correctes et incorrectes)\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Trouver des exemples corrects et incorrects\n",
    "        correct_indices = np.where(y_pred == y_test)[0]\n",
    "        incorrect_indices = np.where(y_pred != y_test)[0]\n",
    "        \n",
    "        # Limiter le nombre d'exemples à afficher\n",
    "        num_examples = min(3, len(correct_indices), len(incorrect_indices))\n",
    "        \n",
    "        if num_examples > 0:\n",
    "            # Sélectionner des exemples aléatoires\n",
    "            correct_samples = np.random.choice(correct_indices, num_examples, replace=False)\n",
    "            incorrect_samples = np.random.choice(incorrect_indices, num_examples, replace=False)\n",
    "            \n",
    "            # Afficher les exemples corrects\n",
    "            for i, idx in enumerate(correct_samples):\n",
    "                plt.subplot(2, num_examples, i + 1)\n",
    "                plt.imshow(X_test[idx])\n",
    "                true_label = class_names[y_test[idx]]\n",
    "                pred_label = class_names[y_pred[idx]]\n",
    "                plt.title(f\"Correct\\nVrai: {true_label}\\nPréd: {pred_label}\\nConf: {y_pred_proba[idx]:.2f}\")\n",
    "                plt.axis('off')\n",
    "            \n",
    "            # Afficher les exemples incorrects\n",
    "            for i, idx in enumerate(incorrect_samples):\n",
    "                plt.subplot(2, num_examples, num_examples + i + 1)\n",
    "                plt.imshow(X_test[idx])\n",
    "                true_label = class_names[y_test[idx]]\n",
    "                pred_label = class_names[y_pred[idx]]\n",
    "                plt.title(f\"Incorrect\\nVrai: {true_label}\\nPréd: {pred_label}\\nConf: {y_pred_proba[idx]:.2f}\")\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.suptitle(f\"Exemples de prédictions - {model_name}\", fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.subplots_adjust(top=0.9)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Pas assez d'exemples pour afficher des prédictions.\")\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'évaluation du modèle {model_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Évaluer chaque modèle (si disponible)\n",
    "models = {}\n",
    "\n",
    "# Vérifier si les modèles existent avant de les ajouter au dictionnaire\n",
    "# Ces variables doivent être définies avant d'exécuter ce code\n",
    "try:\n",
    "    if 'cnn_model' in globals() and cnn_model is not None:\n",
    "        models['CNN'] = cnn_model\n",
    "except NameError:\n",
    "    print(\"Le modèle CNN n'est pas défini.\")\n",
    "\n",
    "try:\n",
    "    if 'vgg16_model' in globals() and vgg16_model is not None:\n",
    "        models['VGG16'] = vgg16_model\n",
    "except NameError:\n",
    "    print(\"Le modèle VGG16 n'est pas défini.\")\n",
    "\n",
    "try:\n",
    "    if 'resnet50_model' in globals() and resnet50_model is not None:\n",
    "        models['ResNet50'] = resnet50_model\n",
    "except NameError:\n",
    "    print(\"Le modèle ResNet50 n'est pas défini.\")\n",
    "\n",
    "# Vérifier si les données de test sont disponibles\n",
    "if 'X_test' not in globals() or 'y_test' not in globals() or len(X_test) == 0:\n",
    "    print(\"Les données de test ne sont pas disponibles. Impossible d'évaluer les modèles.\")\n",
    "else:\n",
    "    # Si aucun modèle n'est disponible, afficher un message\n",
    "    if not models:\n",
    "        print(\"Aucun modèle n'est disponible pour l'évaluation. Vous devez d'abord entraîner les modèles.\")\n",
    "    else:\n",
    "        # Libérer la mémoire avant l'évaluation\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        results = {}\n",
    "        for model_name, model in models.items():\n",
    "            print(f\"\\nÉvaluation du modèle {model_name}...\")\n",
    "            result = evaluate_model(model, X_test, y_test, model_name)\n",
    "            if result is not None:\n",
    "                results[model_name] = result\n",
    "            \n",
    "            # Libérer la mémoire après chaque évaluation\n",
    "            gc.collect()\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "        # Créer un DataFrame pour comparer les métriques si des résultats sont disponibles\n",
    "        if results:\n",
    "            metrics_df = pd.DataFrame(results).T\n",
    "            metrics_df = metrics_df[['accuracy', 'precision', 'recall', 'f1_score', 'auc']]\n",
    "\n",
    "            # Afficher le tableau de comparaison\n",
    "            print(\"\\nComparaison des métriques:\")\n",
    "            print(\"=\" * 50)\n",
    "            print(metrics_df)\n",
    "\n",
    "            # Visualiser les métriques sous forme de graphique à barres\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            ax = metrics_df.plot(kind='bar', figsize=(12, 8))\n",
    "            plt.title('Comparaison des métriques par modèle', fontsize=14)\n",
    "            plt.xlabel('Modèle', fontsize=12)\n",
    "            plt.ylabel('Score', fontsize=12)\n",
    "            plt.ylim(0, 1)\n",
    "            plt.legend(loc='lower right', fontsize=10)\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Ajouter les valeurs sur les barres\n",
    "            for container in ax.containers:\n",
    "                ax.bar_label(container, fmt='%.3f', fontsize=8)\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Sauvegarder les résultats dans un fichier CSV\n",
    "            try:\n",
    "                results_dir = r'C:\\Users\\Krikri\\Documents\\EPITECH\\MSc\\Msc1\\T-DEV-810-PAR-29\\epitech_docs\\detection_pneumonie_ia\\results'\n",
    "                os.makedirs(results_dir, exist_ok=True)\n",
    "                metrics_df.to_csv(os.path.join(results_dir, 'model_comparison.csv'))\n",
    "                print(f\"Résultats sauvegardés dans {os.path.join(results_dir, 'model_comparison.csv')}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de la sauvegarde des résultats: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisation des prédictions\n",
    "\n",
    "Nous allons visualiser quelques exemples de prédictions pour mieux comprendre les performances des modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, X_test, y_test, model_name='Modèle', num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualise quelques prédictions du modèle.\n",
    "    \n",
    "    Args:\n",
    "        model: Modèle à utiliser pour les prédictions\n",
    "        X_test (numpy.ndarray): Images de test\n",
    "        y_test (numpy.ndarray): Étiquettes de test\n",
    "        model_name (str): Nom du modèle\n",
    "        num_samples (int): Nombre d'exemples à visualiser\n",
    "    \"\"\"\n",
    "    # Vérifier si le modèle et les données sont disponibles\n",
    "    if model is None:\n",
    "        print(f\"Le modèle {model_name} n'est pas disponible.\")\n",
    "        return\n",
    "    \n",
    "    if len(X_test) == 0 or len(y_test) == 0:\n",
    "        print(f\"Les données de test sont vides. Impossible de visualiser les prédictions du modèle {model_name}.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Limiter le nombre d'échantillons au nombre d'exemples disponibles\n",
    "        num_samples = min(num_samples, len(X_test))\n",
    "        \n",
    "        # Faire des prédictions avec un batch_size adapté au modèle\n",
    "        batch_size = 16\n",
    "        if 'resnet' in model_name.lower() or 'vgg' in model_name.lower():\n",
    "            batch_size = 8\n",
    "        \n",
    "        print(f\"Prédiction sur {num_samples} images de test...\")\n",
    "        y_pred_proba = model.predict(X_test, batch_size=batch_size, verbose=0).flatten()\n",
    "        y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "        \n",
    "        # Sélectionner différents types d'exemples\n",
    "        # 1. Exemples correctement classifiés (vrais positifs et vrais négatifs)\n",
    "        correct_indices = np.where(y_pred == y_test)[0]\n",
    "        # 2. Exemples incorrectement classifiés (faux positifs et faux négatifs)\n",
    "        incorrect_indices = np.where(y_pred != y_test)[0]\n",
    "        \n",
    "        # Vérifier s'il y a des exemples incorrects\n",
    "        has_incorrect = len(incorrect_indices) > 0\n",
    "        \n",
    "        # Déterminer le nombre d'exemples à afficher de chaque type\n",
    "        num_incorrect = min(num_samples // 2, len(incorrect_indices)) if has_incorrect else 0\n",
    "        num_correct = num_samples - num_incorrect\n",
    "        \n",
    "        # Sélectionner les indices\n",
    "        selected_indices = []\n",
    "        \n",
    "        if num_correct > 0 and len(correct_indices) > 0:\n",
    "            selected_indices.extend(np.random.choice(correct_indices, num_correct, replace=False))\n",
    "        \n",
    "        if num_incorrect > 0:\n",
    "            selected_indices.extend(np.random.choice(incorrect_indices, num_incorrect, replace=False))\n",
    "        \n",
    "        # Si nous n'avons pas assez d'exemples, compléter avec des exemples aléatoires\n",
    "        if len(selected_indices) < num_samples:\n",
    "            remaining = num_samples - len(selected_indices)\n",
    "            all_indices = np.arange(len(X_test))\n",
    "            remaining_indices = np.setdiff1d(all_indices, selected_indices)\n",
    "            if len(remaining_indices) > 0:\n",
    "                selected_indices.extend(np.random.choice(remaining_indices, min(remaining, len(remaining_indices)), replace=False))\n",
    "        \n",
    "        # Mélanger les indices pour ne pas avoir tous les exemples corrects puis tous les incorrects\n",
    "        np.random.shuffle(selected_indices)\n",
    "        \n",
    "        # Visualiser les exemples\n",
    "        plt.figure(figsize=(15, 3 * min(num_samples, len(selected_indices))))\n",
    "        \n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            plt.subplot(min(num_samples, len(selected_indices)), 1, i+1)\n",
    "            \n",
    "            # Afficher l'image\n",
    "            plt.imshow(X_test[idx])\n",
    "            \n",
    "            # Déterminer la couleur en fonction de la prédiction\n",
    "            is_correct = y_pred[idx] == y_test[idx]\n",
    "            color = 'green' if is_correct else 'red'\n",
    "            \n",
    "            # Déterminer les libellés des classes\n",
    "            true_label = 'Pneumonie' if y_test[idx] == 1 else 'Normal'\n",
    "            pred_label = 'Pneumonie' if y_pred[idx] == 1 else 'Normal'\n",
    "            \n",
    "            # Ajouter le type d'erreur si la prédiction est incorrecte\n",
    "            error_type = \"\"\n",
    "            if not is_correct:\n",
    "                if y_test[idx] == 0 and y_pred[idx] == 1:\n",
    "                    error_type = \" (Faux Positif)\"\n",
    "                else:\n",
    "                    error_type = \" (Faux Négatif)\"\n",
    "            \n",
    "            # Afficher le titre avec les informations de prédiction\n",
    "            plt.title(f\"Vrai: {true_label}, Prédit: {pred_label}{error_type} (Confiance: {y_pred_proba[idx]:.2f})\", \n",
    "                     color=color, fontsize=10)\n",
    "            \n",
    "            # Désactiver les axes\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Prédictions du modèle {model_name}', fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "        plt.show()\n",
    "        \n",
    "        # Afficher un résumé des performances\n",
    "        correct = np.sum(y_pred == y_test)\n",
    "        total = len(y_test)\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        print(f\"Résumé des performances du modèle {model_name}:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f} ({correct}/{total} prédictions correctes)\")\n",
    "        \n",
    "        # Calculer les métriques par classe\n",
    "        tp = np.sum((y_test == 1) & (y_pred == 1))  # Vrais positifs\n",
    "        tn = np.sum((y_test == 0) & (y_pred == 0))  # Vrais négatifs\n",
    "        fp = np.sum((y_test == 0) & (y_pred == 1))  # Faux positifs\n",
    "        fn = np.sum((y_test == 1) & (y_pred == 0))  # Faux négatifs\n",
    "        \n",
    "        print(f\"Classe 'Normal': {tn}/{tn+fp} prédictions correctes ({tn/(tn+fp)*100:.1f}%)\")\n",
    "        print(f\"Classe 'Pneumonie': {tp}/{tp+fn} prédictions correctes ({tp/(tp+fn)*100:.1f}%)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la visualisation des prédictions du modèle {model_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Visualiser les prédictions pour chaque modèle\n",
    "if 'models' in globals() and models:\n",
    "    # Libérer la mémoire avant de commencer\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nVisualisation des prédictions du modèle {model_name}:\")\n",
    "        visualize_predictions(model, X_test, y_test, model_name)\n",
    "        \n",
    "        # Libérer la mémoire après chaque modèle\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "else:\n",
    "    print(\"Aucun modèle n'est disponible pour visualiser les prédictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons entraîné différents modèles pour la détection de pneumonie à partir d'images radiographiques :\n",
    "1. Un CNN simple\n",
    "2. Un modèle utilisant le transfer learning avec VGG16\n",
    "3. Un modèle utilisant le transfer learning avec ResNet50\n",
    "\n",
    "Nous avons évalué leurs performances sur l'ensemble de test et visualisé les résultats. Les résultats montrent que [à compléter avec vos observations].\n",
    "\n",
    "Les modèles entraînés ont été sauvegardés dans le répertoire `../results` et peuvent être utilisés pour faire des prédictions sur de nouvelles images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons entraîné différents modèles pour la détection de pneumonie à partir d'images radiographiques :\n",
    "1. Un CNN simple\n",
    "2. Un modèle utilisant le transfer learning avec VGG16\n",
    "3. Un modèle utilisant le transfer learning avec ResNet50\n",
    "\n",
    "Nous avons évalué leurs performances sur l'ensemble de test et visualisé les résultats. Les résultats montrent que [à compléter avec vos observations].\n",
    "\n",
    "Les modèles entraînés ont été sauvegardés dans le répertoire `../results` et peuvent être utilisés pour faire des prédictions sur de nouvelles images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
